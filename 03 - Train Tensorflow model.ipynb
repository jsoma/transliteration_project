{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in the data from `new-am.txt`\n",
    "\n",
    "Hopefully this is all of the text we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ORy8sSAawbp-"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "sl1sC6N0wb6K",
    "outputId": "f245a49f-86f6-47a7-bd46-3d8dc13aa5a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 4431040 characters\n"
     ]
    }
   ],
   "source": [
    "# Read, then decode for py2 compat.\n",
    "text = open('new-am.txt', 'rb').read().decode(encoding='utf-8')\n",
    "# length of text is the number of characters in it\n",
    "print ('Length of text: {} characters'.format(len(text)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "OHjH5-pLwb4g",
    "outputId": "5f753290-685b-44c2-cc9a-c9bf72a07c17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ጠ/ሚ መለስ ዜናዊ \"ጦርነት ኳስ ጨዋታ አይደለም!\" አሉ\n",
      "ሰሞኑን በሕወሓት/ኢሕአዴግ ግምገማ ውስጥ ዋነኛው የግምገማ በትር ያረፈው በጠ/ሚ መለስ ዜናዊ ላይ መሆኑ ተደጋግሞ እየተሰማ ነው።\n",
      "ከዚሁ ጋር ተያይዞ የጠ/ሚንስትሩ ጋርዶች በሌሎች መቀየራቸው፣  ከአቶ መለስ ዜናዊ ጋር የሚያገናኙ የቤተ መንግሥት የስልክ ግንኙነቶች መቋረጣቸው በሰፊው እየተነገረ ሲሆን፣ማንኛውንም የወቅቱን ጉዳይ አስመልክቶ መ\n"
     ]
    }
   ],
   "source": [
    "print(text[:250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "-KxQb6acwb0e",
    "outputId": "1bd2a40f-fc4b-4721-b404-6c7c1e53b48e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "445 unique characters\n"
     ]
    }
   ],
   "source": [
    "vocab = sorted(set(text))\n",
    "print ('{} unique characters'.format(len(vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mh6d5-GPww9R"
   },
   "outputs": [],
   "source": [
    "# Store \n",
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "\n",
    "text_as_int = np.array([char2idx[c] for c in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f_CqDe3Z1VO_"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('char2idx.json', 'w') as f:\n",
    "  json.dump(char2idx, f)\n",
    "\n",
    "with open('idx2char.json', 'w') as f:\n",
    "  json.dump(list(idx2char), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F-Domfmp1u5j"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "files.download('char2idx.json')\n",
    "files.download('idx2char.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "colab_type": "code",
    "id": "xZ2keHTmwxB1",
    "outputId": "dda0dfa2-f72a-42f2-d741-1de71541cfba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  '\\n':   0,\n",
      "  ' ' :   1,\n",
      "  '!' :   2,\n",
      "  '\"' :   3,\n",
      "  '#' :   4,\n",
      "  '$' :   5,\n",
      "  '%' :   6,\n",
      "  '&' :   7,\n",
      "  \"'\" :   8,\n",
      "  '(' :   9,\n",
      "  ')' :  10,\n",
      "  '*' :  11,\n",
      "  '+' :  12,\n",
      "  ',' :  13,\n",
      "  '-' :  14,\n",
      "  '.' :  15,\n",
      "  '/' :  16,\n",
      "  '0' :  17,\n",
      "  '1' :  18,\n",
      "  '2' :  19,\n",
      "  ...\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print('{')\n",
    "for char,_ in zip(char2idx, range(20)):\n",
    "    print('  {:4s}: {:3d},'.format(repr(char), char2idx[char]))\n",
    "print('  ...\\n}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "HtqHFldvwxFf",
    "outputId": "2cb7e8a7-c2d6-4312-a815-712c23d1c109"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'“የዳታ ፕሮሰሲንግ አ' ---- characters mapped to int ---- > [426 311 321 222   1 396 175 177 179 247 340   1 258]\n"
     ]
    }
   ],
   "source": [
    "print ('{} ---- characters mapped to int ---- > {}'.format(repr(text[:13]), text_as_int[:13]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "Abik3oKRw1pg",
    "outputId": "374f9399-33fd-43b4-fb7d-377e2343ad95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "“\n",
      "የ\n",
      "ዳ\n",
      "ታ\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# The maximum length sentence we want for a single input in characters\n",
    "seq_length = 100\n",
    "examples_per_epoch = len(text)//(seq_length+1)\n",
    "\n",
    "# Create training examples / targets\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
    "\n",
    "for i in char_dataset.take(5):\n",
    "  print(idx2char[i.numpy()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "ns06WfR8w1yI",
    "outputId": "21975e4d-221e-44f7-d39d-01d6dc861ab2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'“የዳታ ፕሮሰሲንግ አገልግሎት” ማለት በኮምፒዩተር ሥርዓት አማካኝነት ዳታን የመቀበል ፣ የማከማቸት ፣ የመተንተን ፣ የማሰራጨት ፣ የማጓጓዝ ወይም የማስተላለፍ '\n",
      "'አገልግሎት ሲሆን የኔትዎርክ አገልግሎችንም\\n“የዳታ ፕሮሰሲንግ አገልግሎት” ማለት በኮምፒዩተር ሥርዓት አማካኝነት ዳታን የመቀበል ፣ የማከማቸት ፣ የመተንተን ፣ '\n",
      "'የማሰራጨት ፣ የማጓጓዝ ወይም የማስተላለፍ አገልግሎት ሲሆን የኔትዎርክ አገልግሎችንም\\nየኤጀንሲው ዓላማ\\nየኤጀንሲው ዓላማ\\nእንዲህ አለው፦ “ዮፍታሔ እንዲህ ይላል፦'\n",
      "' ‘እስራኤል የሞዓባውያንን ምድርና የአሞናውያንን ምድር አልወሰደም ፤\\nእንዲህ አለው፦ “ዮፍታሔ እንዲህ ይላል፦ ‘እስራኤል የሞዓባውያንን ምድርና የአሞናውያንን ም'\n",
      "'ድር አልወሰደም ፤\\nሆኖም ትርፏና የምትቀበለው ክፍያ ለይሖዋ የተቀደሰ ይሆናል ። አይከማችም ወይም አይጠራቀምም ፤ ምክንያቱም በይሖዋ ፊት የሚኖሩ ሰዎች እስኪጠግ'\n"
     ]
    }
   ],
   "source": [
    "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
    "\n",
    "for item in sequences.take(5):\n",
    "  print(repr(''.join(idx2char[item.numpy()])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0f8Qm_sCw2Bt"
   },
   "outputs": [],
   "source": [
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = sequences.map(split_input_target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "jsdXnUXmw19w",
    "outputId": "3cf4b0a0-0c38-4d36-a4c3-bddb4bebcee9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data:  '“የዳታ ፕሮሰሲንግ አገልግሎት” ማለት በኮምፒዩተር ሥርዓት አማካኝነት ዳታን የመቀበል ፣ የማከማቸት ፣ የመተንተን ፣ የማሰራጨት ፣ የማጓጓዝ ወይም የማስተላለፍ'\n",
      "Target data: 'የዳታ ፕሮሰሲንግ አገልግሎት” ማለት በኮምፒዩተር ሥርዓት አማካኝነት ዳታን የመቀበል ፣ የማከማቸት ፣ የመተንተን ፣ የማሰራጨት ፣ የማጓጓዝ ወይም የማስተላለፍ '\n"
     ]
    }
   ],
   "source": [
    "for input_example, target_example in  dataset.take(1):\n",
    "  print ('Input data: ', repr(''.join(idx2char[input_example.numpy()])))\n",
    "  print ('Target data:', repr(''.join(idx2char[target_example.numpy()])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "id": "1J3DnJxIwxUS",
    "outputId": "9f199260-3183-415f-cf08-6e27e30c8d8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step    0\n",
      "  input: 426 ('“')\n",
      "  expected output: 311 ('የ')\n",
      "Step    1\n",
      "  input: 311 ('የ')\n",
      "  expected output: 321 ('ዳ')\n",
      "Step    2\n",
      "  input: 321 ('ዳ')\n",
      "  expected output: 222 ('ታ')\n",
      "Step    3\n",
      "  input: 222 ('ታ')\n",
      "  expected output: 1 (' ')\n",
      "Step    4\n",
      "  input: 1 (' ')\n",
      "  expected output: 396 ('ፕ')\n"
     ]
    }
   ],
   "source": [
    "for i, (input_idx, target_idx) in enumerate(zip(input_example[:5], target_example[:5])):\n",
    "    print(\"Step {:4d}\".format(i))\n",
    "    print(\"  input: {} ({:s})\".format(input_idx, repr(idx2char[input_idx])))\n",
    "    print(\"  expected output: {} ({:s})\".format(target_idx, repr(idx2char[target_idx])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "7dNUK-_7wxd5",
    "outputId": "8069d4d3-627b-4ca5-9b1a-cafec895438e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((64, 100), (64, 100)), types: (tf.int64, tf.int64)>"
      ]
     },
     "execution_count": 48,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Batch size\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Buffer size to shuffle the dataset\n",
    "# (TF data is designed to work with possibly infinite sequences,\n",
    "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
    "# it maintains a buffer in which it shuffles elements).\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2VdXVyrcwxS7"
   },
   "outputs": [],
   "source": [
    "# Length of the vocabulary in chars\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# The embedding dimension\n",
    "embedding_dim = 256\n",
    "\n",
    "# Number of RNN units\n",
    "rnn_units = 1024\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K6ciummQxKvK"
   },
   "outputs": [],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "  model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
    "                              batch_input_shape=[batch_size, None]),\n",
    "    tf.keras.layers.GRU(rnn_units,\n",
    "                        return_sequences=True,\n",
    "                        stateful=True,\n",
    "                        recurrent_initializer='glorot_uniform'),\n",
    "    tf.keras.layers.Dense(vocab_size)\n",
    "  ])\n",
    "  return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ys1ANFzoxK-i"
   },
   "outputs": [],
   "source": [
    "model = build_model(\n",
    "  vocab_size = len(vocab),\n",
    "  embedding_dim=embedding_dim,\n",
    "  rnn_units=rnn_units,\n",
    "  batch_size=BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "VX8Y0qXXxLCn",
    "outputId": "614698b9-0978-4eec-874c-5633bbea519e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100, 445) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "  example_batch_predictions = model(input_example_batch)\n",
    "  print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "QEIzSIYCxK7W",
    "outputId": "9c51a703-a20f-47c3-de56-b3fd491b3eed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (64, None, 256)           113920    \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (64, None, 1024)          3938304   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (64, None, 445)           456125    \n",
      "=================================================================\n",
      "Total params: 4,508,349\n",
      "Trainable params: 4,508,349\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "KHb02BG_xYEN",
    "outputId": "444f6821-03be-40c6-a173-d10b0019afd1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape:  (64, 100, 445)  # (batch_size, sequence_length, vocab_size)\n",
      "scalar_loss:       6.099281\n"
     ]
    }
   ],
   "source": [
    "def loss(labels, logits):\n",
    "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "\n",
    "example_batch_loss  = loss(target_example_batch, example_batch_predictions)\n",
    "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
    "print(\"scalar_loss:      \", example_batch_loss.numpy().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E-Siidb6xYCf"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D0pK9n9SxYBE"
   },
   "outputs": [],
   "source": [
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ngS_u_X5xK0w"
   },
   "outputs": [],
   "source": [
    "EPOCHS=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "gOZHdX-axp1s",
    "outputId": "6193ca28-9a31-4101-a36f-b89832d4eb9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1286/1286 [==============================] - 68s 53ms/step - loss: 2.5197\n",
      "Epoch 2/100\n",
      "1286/1286 [==============================] - 68s 53ms/step - loss: 1.8592\n",
      "Epoch 3/100\n",
      "1286/1286 [==============================] - 68s 53ms/step - loss: 1.6989\n",
      "Epoch 4/100\n",
      "1286/1286 [==============================] - 67s 52ms/step - loss: 1.6049\n",
      "Epoch 5/100\n",
      "1286/1286 [==============================] - 68s 53ms/step - loss: 1.5400\n",
      "Epoch 6/100\n",
      "1286/1286 [==============================] - 67s 52ms/step - loss: 1.4933\n",
      "Epoch 7/100\n",
      "1286/1286 [==============================] - 67s 52ms/step - loss: 1.4603\n",
      "Epoch 8/100\n",
      "1286/1286 [==============================] - 67s 52ms/step - loss: 1.4371\n",
      "Epoch 9/100\n",
      "1286/1286 [==============================] - 67s 52ms/step - loss: 1.4203\n",
      "Epoch 10/100\n",
      "1286/1286 [==============================] - 68s 53ms/step - loss: 1.4100\n",
      "Epoch 11/100\n",
      "1286/1286 [==============================] - 67s 52ms/step - loss: 1.4029\n",
      "Epoch 12/100\n",
      "1286/1286 [==============================] - 67s 52ms/step - loss: 1.3986\n",
      "Epoch 13/100\n",
      "1286/1286 [==============================] - 67s 52ms/step - loss: 1.3982\n",
      "Epoch 14/100\n",
      "1286/1286 [==============================] - 67s 52ms/step - loss: 1.3969\n",
      "Epoch 15/100\n",
      "1286/1286 [==============================] - 67s 52ms/step - loss: 1.3983\n",
      "Epoch 16/100\n",
      "1286/1286 [==============================] - 67s 52ms/step - loss: 1.4028\n",
      "Epoch 17/100\n",
      "1286/1286 [==============================] - 67s 52ms/step - loss: 1.4121\n",
      "Epoch 18/100\n",
      "1286/1286 [==============================] - 67s 52ms/step - loss: 1.4129\n",
      "Epoch 19/100\n",
      "1286/1286 [==============================] - 67s 52ms/step - loss: 1.4177\n",
      "Epoch 20/100\n",
      "1286/1286 [==============================] - 67s 52ms/step - loss: 1.4250\n",
      "Epoch 21/100\n",
      "1286/1286 [==============================] - 66s 52ms/step - loss: 1.4363\n",
      "Epoch 22/100\n",
      "1286/1286 [==============================] - 67s 52ms/step - loss: 1.4616\n",
      "Epoch 23/100\n",
      "1286/1286 [==============================] - 67s 52ms/step - loss: 1.4843\n",
      "Epoch 24/100\n",
      "1286/1286 [==============================] - 68s 53ms/step - loss: 1.4908\n",
      "Epoch 25/100\n",
      "1286/1286 [==============================] - 68s 53ms/step - loss: 1.4907\n",
      "Epoch 26/100\n",
      "1286/1286 [==============================] - 67s 52ms/step - loss: 1.5006\n",
      "Epoch 27/100\n",
      "1286/1286 [==============================] - 66s 51ms/step - loss: 1.5221\n",
      "Epoch 28/100\n",
      "1286/1286 [==============================] - 67s 52ms/step - loss: 1.5362\n",
      "Epoch 29/100\n",
      "1286/1286 [==============================] - 67s 52ms/step - loss: 1.5806\n",
      "Epoch 30/100\n",
      "1286/1286 [==============================] - 67s 52ms/step - loss: 1.7482\n",
      "Epoch 31/100\n",
      "1286/1286 [==============================] - 67s 52ms/step - loss: 1.8220\n",
      "Epoch 32/100\n",
      "1286/1286 [==============================] - 67s 52ms/step - loss: 1.8229\n",
      "Epoch 33/100\n",
      "1286/1286 [==============================] - 67s 52ms/step - loss: 1.8848\n",
      "Epoch 34/100\n",
      "1286/1286 [==============================] - 67s 52ms/step - loss: 1.8854\n",
      "Epoch 35/100\n",
      "1286/1286 [==============================] - 67s 52ms/step - loss: 2.6301\n",
      "Epoch 36/100\n",
      "1286/1286 [==============================] - 67s 52ms/step - loss: 2.5165\n",
      "Epoch 37/100\n",
      "1286/1286 [==============================] - 67s 52ms/step - loss: 2.4995\n",
      "Epoch 38/100\n",
      "1286/1286 [==============================] - 67s 52ms/step - loss: 2.4712\n",
      "Epoch 39/100\n",
      "1286/1286 [==============================] - 67s 52ms/step - loss: 2.4710\n",
      "Epoch 40/100\n",
      "1286/1286 [==============================] - 67s 52ms/step - loss: 2.4426\n",
      "Epoch 41/100\n",
      "1286/1286 [==============================] - 67s 52ms/step - loss: 2.3995\n",
      "Epoch 42/100\n",
      "1286/1286 [==============================] - 67s 52ms/step - loss: 2.3461\n",
      "Epoch 43/100\n",
      "1286/1286 [==============================] - 67s 52ms/step - loss: 2.2792\n",
      "Epoch 44/100\n",
      " 736/1286 [================>.............] - ETA: 29s - loss: 2.2253"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fQqxn7kPEMMY"
   },
   "outputs": [],
   "source": [
    "tf.train.latest_checkpoint(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iLFflmtLEMd_"
   },
   "outputs": [],
   "source": [
    "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "\n",
    "model.build(tf.TensorShape([1, None]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sEzOOfTHmSbB"
   },
   "outputs": [],
   "source": [
    "!rm -rf char_model\n",
    "model.save(\"char_model\")\n",
    "!tar -zcvf char_model.tar.gz char_model\n",
    "\n",
    "from google.colab import files\n",
    "files.download('char_model.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Uf0XpcnoGcKx"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "02-OpenNMT training by full sentences.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
