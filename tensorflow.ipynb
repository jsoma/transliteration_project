{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ORy8sSAawbp-"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversion tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f_CqDe3Z1VO_"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('lat_eth.json') as f:\n",
    "    lat_eth = json.load(f)\n",
    "\n",
    "eth2lat = {}\n",
    "for lat in lat_eth.keys():\n",
    "    for eth in lat_eth[lat]:\n",
    "        if eth not in eth2lat.keys():\n",
    "            eth2lat[eth] = []\n",
    "        eth2lat[eth].append(lat)\n",
    "\n",
    "for key in eth2lat.keys():\n",
    "    eth2lat[key] = set(eth2lat[key])\n",
    "\n",
    "with open('char2idx.json') as f:\n",
    "    char2idx = json.load(f)\n",
    "\n",
    "with open('idx2char.json') as f:\n",
    "    idx2char = np.array(json.load(f))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "6UNFupcc6LQn",
    "outputId": "62723844-b11d-4751-f2e0-7fdae3026d07"
   },
   "outputs": [],
   "source": [
    "# Used a custom loss function so we need to load_model without compilation\n",
    "def loss(labels, logits):\n",
    "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "\n",
    "model = tf.keras.models.load_model(\"char_model_wiki\", compile=False)\n",
    "model.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability calculations\n",
    "\n",
    "Softmax converts the predictions into probabilities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.88072e-06"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert predictions to probabilities\n",
    "\n",
    "cont_cached = {}\n",
    "\n",
    "def get_next_char_probs(start_string):\n",
    "    cache_key = start_string\n",
    "    if cache_key in cont_cached.keys():\n",
    "        pred_prob = cont_cached[cache_key]\n",
    "    else:\n",
    "        input_eval = [char2idx[s] for s in start_string]\n",
    "        input_eval = tf.expand_dims(input_eval, 0)\n",
    "        print(\"input_eval is\", input_eval)\n",
    "        # Ask model to evaluate what's next, given start_string\n",
    "        model.reset_states()\n",
    "        predictions = model(input_eval)\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "        \n",
    "        # Convert scores to probabilities\n",
    "        pred_prob = tf.nn.softmax(predictions[0])\n",
    "\n",
    "        # Cache probabilities\n",
    "        cont_cached[cache_key] = pred_prob\n",
    "    return pred_prob\n",
    "\n",
    "def continuation_proba(start_string, next_char):\n",
    "    try:\n",
    "        # Index of target for when we pull it out of the scores\n",
    "        target_idx = char2idx[next_char]\n",
    "    except:\n",
    "        # If we've never seen that char before, get out of here!\n",
    "        return 0\n",
    "    \n",
    "    # Check the cache\n",
    "    cache_key = start_string\n",
    "    if cache_key in cont_cached.keys():\n",
    "        pred_prob = cont_cached[cache_key]\n",
    "    else:\n",
    "        # Convert characters into indices for tensorflow processing\n",
    "        try:\n",
    "            input_eval = [char2idx[s] for s in start_string]\n",
    "        except:\n",
    "            # We've never seen it!!! just exit!!\n",
    "            return 0\n",
    "\n",
    "        input_eval = tf.expand_dims(input_eval, 0)\n",
    "\n",
    "        # Ask model to evaluate what's next, given start_string\n",
    "        model.reset_states()\n",
    "        predictions = model(input_eval)\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "        \n",
    "        # Convert scores to probabilities\n",
    "        pred_prob = tf.nn.softmax(predictions[0])\n",
    "\n",
    "        # Cache probabilities\n",
    "        cont_cached[cache_key] = pred_prob\n",
    "\n",
    "    \n",
    "    proba = pred_prob[target_idx].numpy()\n",
    "    return proba\n",
    "\n",
    "start_string = \"ኢንኢድኢህኢ\"\n",
    "next_char = \"ን\"\n",
    "\n",
    "continuation_proba(start_string, next_char)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probability of each step multiplied out\n",
    "\n",
    "Currently does not adjust for length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted for length:\n",
      "1.2738985333271557e-06\n",
      "2.6276173969082115e-13\n",
      "1.7058100856634426e-13\n",
      "\n",
      "Not adjusted for length:\n",
      "6.369492666635779e-07\n",
      "8.758724656360705e-14\n",
      "5.686033618878142e-14\n",
      "CPU times: user 52.2 ms, sys: 4.62 ms, total: 56.8 ms\n",
      "Wall time: 334 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "cached = {}\n",
    "\n",
    "def text_proba(text, length_adj=False):\n",
    "    # Check the cache\n",
    "    cache_key = text + (\"-adj\" if length_adj else \"-unadj\")\n",
    "    if cache_key in cached.keys():\n",
    "        return cached[cache_key]\n",
    "\n",
    "    # Otherwise we'll calculate the probability\n",
    "    proba = 1\n",
    "    for i in range(1, len(text)):\n",
    "        base_str = text[:i]\n",
    "        next_char = text[i]\n",
    "        proba = proba * continuation_proba(base_str, next_char)\n",
    "\n",
    "    # Adjust for length\n",
    "    if length_adj:\n",
    "        proba = len(text) * proba\n",
    "\n",
    "    # Store in cache\n",
    "    cached[cache_key] = proba\n",
    "    return proba\n",
    "\n",
    "print(\"Adjusted for length:\")\n",
    "print(text_proba(\"ጭም\", length_adj=True))\n",
    "print(text_proba(\"ጭምቅ\", length_adj=True))\n",
    "print(text_proba(\"ጭምኢ\", length_adj=True))\n",
    "\n",
    "print(\"\\nNot adjusted for length:\")\n",
    "print(text_proba(\"ጭም\", length_adj=False))\n",
    "print(text_proba(\"ጭምቅ\", length_adj=False))\n",
    "print(text_proba(\"ጭምኢ\", length_adj=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "# REMOVED because the greedy one (below) works better\n",
    "# but left here for posterity\n",
    "#\n",
    "#\n",
    "\n",
    "# %%time\n",
    "# import itertools\n",
    "# MAX_SEQ_LENGTH = 5\n",
    "\n",
    "# def predict(sequence, base=None):\n",
    "#     # print(\"Base of\", base)\n",
    "#     if len(sequence) > MAX_SEQ_LENGTH:\n",
    "#         starters = predict(sequence[:MAX_SEQ_LENGTH], base)\n",
    "#         overall_results = []\n",
    "#         for r in starters:\n",
    "#             if base:\n",
    "#                 text = base + r[0]\n",
    "#             else:\n",
    "#                 text = r[0]\n",
    "#             results = predict(sequence[MAX_SEQ_LENGTH:], text)\n",
    "#             overall_results.extend(results)\n",
    "#         return sorted(overall_results,\n",
    "#                       key=lambda result: result[1],\n",
    "#                       reverse=True)[:5]\n",
    "#     else:\n",
    "#         expanded = itertools.product(*sequence[:MAX_SEQ_LENGTH])\n",
    "#         amharic_options = [''.join(chars) for chars in expanded]\n",
    "#         if base:\n",
    "#             amharic_options = [base + text for text in amharic_options]\n",
    "#         scores = []\n",
    "#         for possible in amharic_options:\n",
    "#             scores.append(text_proba(''.join(possible)))\n",
    "        \n",
    "#         top_5 = np.argsort(scores)[-5:][::-1]\n",
    "#         amharic_options = np.array(amharic_options)\n",
    "#         scores = np.array(scores)\n",
    "        \n",
    "#         return list(zip(amharic_options[top_5], scores[top_5]))\n",
    "\n",
    "# def breakdown_and_predict(text):\n",
    "#     top_fives = []\n",
    "#     for segmentation in tqdm_notebook(get_breakdowns(text), position=0):\n",
    "#         options = [lat_eth[segment] for segment in segmentation]\n",
    "#         top_five = predict(options)\n",
    "#         top_fives.extend(top_five)\n",
    "\n",
    "#     # We'll return the top 10 top fives\n",
    "#     return sorted(top_fives,\n",
    "#               key=lambda result: result[1],\n",
    "#               reverse=True)[:10]\n",
    "\n",
    "# # ጥበብን\n",
    "# breakdown_and_predict(\"tibebini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_breakdowns(segment):\n",
    "    # Remove apostrophes\n",
    "    options = []\n",
    "    max_len = min([len(segment), 4])\n",
    "    for i in range(1, max_len+1):\n",
    "        potential = segment[:i]\n",
    "        if potential in lat_eth.keys():\n",
    "            remainder = segment[i:]\n",
    "            if remainder == \"\":\n",
    "                options.append([potential])\n",
    "            else:\n",
    "                enders = calc_breakdowns(remainder)\n",
    "                if enders == []:\n",
    "                    return []\n",
    "                else:\n",
    "                    options.extend([potential, *e] for e in enders)\n",
    "    return options\n",
    "\n",
    "def get_breakdowns(segment):\n",
    "    results = calc_breakdowns(segment)\n",
    "    if len(results) == 0:\n",
    "        results = calc_breakdowns(segment.replace(\"'\", \"\").replace(\"`\", \"\"))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['i', 'n', 'i', 'd', 'i', 'h', 'i'],\n",
       " ['i', 'n', 'i', 'd', 'i', 'hi'],\n",
       " ['i', 'n', 'i', 'di', 'h', 'i'],\n",
       " ['i', 'n', 'i', 'di', 'hi'],\n",
       " ['i', 'ni', 'd', 'i', 'h', 'i'],\n",
       " ['i', 'ni', 'd', 'i', 'hi'],\n",
       " ['i', 'ni', 'di', 'h', 'i'],\n",
       " ['i', 'ni', 'di', 'hi']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breakdowns = get_breakdowns(\"inidihi\")\n",
    "breakdowns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semi-greedy algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that text_proba does NOT work with single chars, so this might be off at some points?\n",
    "\n",
    "## `best_next_steps`\n",
    "\n",
    "It's like \"given a string, what's our next best character option?\", except we allow for multiple inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a list of 'current' states (e.g. top 3 'tibe' options)\n",
    "# And a list of things to add on (e.g. all 'bi' options)\n",
    "# What are the best n options for 'tibebi'\n",
    "def best_next_steps(current_states, next_options, n=3):\n",
    "    # Pairs keeps track of all texts + probabilities\n",
    "    pairs = []\n",
    "    \n",
    "    # From each possible \n",
    "    for base in current_states:\n",
    "        # Create all the text options we're looking at\n",
    "        # Then calculate their probability\n",
    "        texts = [f\"{base}{follower}\" for follower in next_options]\n",
    "        probs = [text_proba(text) for text in texts]\n",
    "        pairs.extend(zip(texts, probs))\n",
    "    \n",
    "    # Only return the top n options\n",
    "    top = sorted(pairs, key=lambda pair: pair[1], reverse=True)[:n]\n",
    "\n",
    "    return top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `get_top_sequences` and `get_top_sequences_all`\n",
    "\n",
    "Given a breakdown (or a list of breakdowns), what are the best Ethiopic options? Greedy-ish, only follows the top 3 by default but you can adjust it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "\n",
    "# Receive a list like ['ti', 'be', 'bi', 'ni']\n",
    "# Tries out each Ethiopic option, returns top n most likely\n",
    "def get_top_sequences(breakdown, n=3, lower_bound=None):\n",
    "    eth_poss = [lat_eth[latin] for latin in breakdown]\n",
    "\n",
    "    # current = eth_poss[0]\n",
    "    # for next_options in eth_poss[1:]:\n",
    "    # Starts with a space bc beginning of word\n",
    "    current = \" \"\n",
    "    for next_options in eth_poss:\n",
    "        # If it's a space take all options\n",
    "        n_steps = 10 if current == \" \" else n\n",
    "        top = best_next_steps(current, next_options, n_steps)\n",
    "\n",
    "        # Only keep ones above lower score bound\n",
    "        # if you want to use them all, lower_bound should be None\n",
    "        if lower_bound != None:\n",
    "            current = [option[0] for option in top if option[1] >= lower_bound]\n",
    "            # For debugging\n",
    "            dropped = len(top) - len(current)\n",
    "        else:\n",
    "            current = [option[0] for option in top]\n",
    "    \n",
    "    # Remove spaces\n",
    "    top = [(option[0][1:], option[1]) for option in top]\n",
    "    return top\n",
    "\n",
    "# Takes a list of potential breakdowns\n",
    "# n is passed to get_top_sequences\n",
    "# limit is used here\n",
    "def get_top_sequences_all(breakdowns, limit=5, n=5):\n",
    "    tops = []\n",
    "    \n",
    "    # shorter breakdowns go first\n",
    "    breakdowns = sorted(breakdowns, key=lambda breakdown: len(breakdowns))\n",
    "\n",
    "    lower_bound = 0\n",
    "    # Visual readout of length\n",
    "#     for breakdown in tqdm_notebook(breakdowns):\n",
    "    for breakdown in breakdowns:\n",
    "        top = get_top_sequences(breakdown, n, lower_bound=lower_bound)\n",
    "        if len(top) > 0:\n",
    "            worst_score = top[-1][1]\n",
    "            if worst_score > lower_bound:\n",
    "                lower_bound = worst_score\n",
    "            tops.extend(top)\n",
    "        \n",
    "    return sorted(tops, key=lambda pair: pair[1], reverse=True)[:limit]\n",
    "\n",
    "# Given Latin script, what is the best Ethiopic?\n",
    "def top_transcriptions(text, limit=5, n=5):\n",
    "    breakdowns = get_breakdowns(text)\n",
    "    return get_top_sequences_all(breakdowns, limit, n)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples of everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['t', 'i', 'b', 'e', 'b', 'i', 'n', 'i'],\n",
       " ['t', 'i', 'b', 'e', 'b', 'i', 'ni'],\n",
       " ['t', 'i', 'b', 'e', 'bi', 'n', 'i'],\n",
       " ['t', 'i', 'b', 'e', 'bi', 'ni'],\n",
       " ['t', 'i', 'be', 'b', 'i', 'n', 'i'],\n",
       " ['t', 'i', 'be', 'b', 'i', 'ni'],\n",
       " ['t', 'i', 'be', 'bi', 'n', 'i'],\n",
       " ['t', 'i', 'be', 'bi', 'ni'],\n",
       " ['ti', 'b', 'e', 'b', 'i', 'n', 'i'],\n",
       " ['ti', 'b', 'e', 'b', 'i', 'ni'],\n",
       " ['ti', 'b', 'e', 'bi', 'n', 'i'],\n",
       " ['ti', 'b', 'e', 'bi', 'ni'],\n",
       " ['ti', 'be', 'b', 'i', 'n', 'i'],\n",
       " ['ti', 'be', 'b', 'i', 'ni'],\n",
       " ['ti', 'be', 'bi', 'n', 'i'],\n",
       " ['ti', 'be', 'bi', 'ni']]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting potential breakdowns\n",
    "get_breakdowns('tibebini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['ኢ', 'እ', 'ዒ', 'ዕ'],\n",
       " ['ኒ', 'ን', 'ኚ', 'ኝ'],\n",
       " ['ዲ', 'ድ', 'ዺ', 'ፂ'],\n",
       " ['ሂ', 'ህ', 'ሒ', 'ሕ', 'ኂ', 'ኅ', 'ኺ', 'ኽ', 'ⷒ']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting from latin to potential ethiopic\n",
    "# (only works for one breakdown at a time)\n",
    "breakdown = breakdowns[-1]\n",
    "[lat_eth[segment] for segment in breakdown]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1294759933652892e-13"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate text probability\n",
    "text_proba('ጥበብ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ትበቢ', 8.690577709569554e-11),\n",
       " ('ትበብ', 6.622375520165555e-11),\n",
       " ('ጥብቢ', 1.372473027387372e-11)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Given the starting options of ['ጥበ', 'ጥብ', 'ትበ']\n",
    "# What options out of ['ቢ', 'ብ'] are the best next step?\n",
    "best_next_steps(\n",
    "    ['ጥበ', 'ጥብ', 'ትበ'],\n",
    "    ['ቢ', 'ብ']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking at ['i', 'ni', 'di', 'hi']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('ዕኝድኽ', 1.62357156335283e-13),\n",
       " ('ዕኝድሂ', 7.477636447044843e-14),\n",
       " ('ዕኝድህ', 7.429985103788478e-14),\n",
       " ('ዕኝዲኽ', 7.153003101312422e-14),\n",
       " ('ዒኝድኽ', 6.501592972821455e-14)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get_top_sequences gets the top n options for a breakdown\n",
    "print(\"Looking at\", breakdown)\n",
    "get_top_sequences(breakdown, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking at 8 breakdowns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('ዕኝድኽ', 1.62357156335283e-13),\n",
       " ('ዕኝድሂ', 7.477636447044843e-14),\n",
       " ('ዕኝድህ', 7.429985103788478e-14),\n",
       " ('ዕኝዲኽ', 7.153003101312422e-14),\n",
       " ('ዒኝድኽ', 6.501592972821455e-14),\n",
       " ('ዕኝዕድኽ', 3.1332750462177764e-16),\n",
       " ('ዕኝድዕኽ', 3.133273723157534e-16),\n",
       " ('ዕኝዕድሂ', 1.4430833979273464e-16),\n",
       " ('ዕኝድዕሂ', 1.4430827885693287e-16),\n",
       " ('ዕኝዕድህ', 1.4338873287109334e-16)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get_top_sequences_all does it for multiple breakdowns\n",
    "print(\"Looking at\", len(breakdowns), \"breakdowns\")\n",
    "get_top_sequences_all(breakdowns, limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking at 8 breakdowns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('ዕኝድኽ', 1.62357156335283e-13),\n",
       " ('ዕኝድሂ', 7.477636447044843e-14),\n",
       " ('ዕኝድህ', 7.429985103788478e-14),\n",
       " ('ዕኝዲኽ', 7.153003101312422e-14),\n",
       " ('ዒኝድኽ', 6.501592972821455e-14),\n",
       " ('ዕኝዕድኽ', 3.1332750462177764e-16),\n",
       " ('ዕኝድዕኽ', 3.133273723157534e-16),\n",
       " ('ዕኝዕድሂ', 1.4430833979273464e-16),\n",
       " ('ዕኝድዕሂ', 1.4430827885693287e-16),\n",
       " ('ዕኝዕድህ', 1.4338873287109334e-16)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get_top_sequences_all does it for multiple breakdowns\n",
    "print(\"Looking at\", len(breakdowns), \"breakdowns\")\n",
    "get_top_sequences_all(breakdowns, limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ጥብብ', 3.4980477533301296e-11),\n",
       " ('ጥበብ', 1.479104984137833e-11),\n",
       " ('ጢብብ', 9.103798573178485e-12),\n",
       " ('ጥቤብ', 5.090075612385105e-12),\n",
       " ('ጢበብ', 3.849425392022195e-12)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_transcriptions(\"tibebi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Worst-case scenario, totally cleared cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_cached = {}\n",
    "cached = {}\n",
    "\n",
    "# The cache will fill up as we go along, so\n",
    "# this word won't always take so long\n",
    "#top_transcriptions(\"yamijadarguatkhawini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actual transliterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def tokenize_text(text):\n",
    "    sentence = [i for j in text.split() for i in (j, ' ')][:-1]\n",
    "    cleaned = []\n",
    "    for elmt in sentence:\n",
    "        elmt_tokenized = word_tokenize(elmt)\n",
    "        if elmt == ' ':\n",
    "            cleaned.append(' ')\n",
    "        elif len(elmt) == len(elmt_tokenized):\n",
    "            cleaned.append(elmt)\n",
    "        else:\n",
    "            for i in elmt_tokenized:\n",
    "                if i == \"'\":\n",
    "                    elmt_tokenized.remove(i)\n",
    "                cleaned += elmt_tokenized\n",
    "\n",
    "    return cleaned\n",
    "\n",
    "def transliterate(text):\n",
    "    sent_trans = []\n",
    "\n",
    "    cleaned = tokenize_text(text)\n",
    "    for word in cleaned:\n",
    "        sent_trans.append(transliterate_word(word))\n",
    "    \n",
    "    return \"\".join(sent_trans)\n",
    "\n",
    "def transliterate_word(word, top_n=1):\n",
    "    if word.isspace():\n",
    "        return word\n",
    "    if word in lat_eth.keys() and len(lat_eth[word]) == 0:\n",
    "        return lat_eth[word][0]\n",
    "    elif word in string.punctuation:\n",
    "        return word\n",
    "    elif word.isnumeric() == True:\n",
    "        return word\n",
    "    else:\n",
    "        cleaned = word.lower()\n",
    "        results = top_transcriptions(cleaned)\n",
    "        if len(results) == 0:\n",
    "            cleaned = re.sub(r'[^a-z]', '', cleaned)\n",
    "            results = top_transcriptions(cleaned)\n",
    "\n",
    "        if top_n == 1:\n",
    "            return results[0][0]\n",
    "        else:\n",
    "            return [result[0] for result in results[:top_n]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ጥብኝኝ'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transliterate_word(\"tibenini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ጥብኝኝ', 'ጥበኝኝ']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transliterate_word(\"tibenini\", top_n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ጥብኝኝ'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transliterate(\"tibenini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ዕኝድኽ ሽል . ኹለጥ ሽዖጪ ልሽልዩ ዋዴ'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transliterate(\"inidihi sil . hulat sewochi liseliyu wade\")\n",
    "#እንዲህ ሲል ። ሁለት ሰዎች ሊጸልዩ ወደ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ዕያሱጽሜ . ዕዌኝጥ ዕውኛጥ ዕለጬኋልኹ'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transliterate(\"ijasusme . 'eweneti iwnat `elacehualehu\")\n",
    "#ኢየሱስም ። እውነት እውነት እላችኋለሁ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ዕያሱጽሜ', 9.281910896609981e-18),\n",
       " ('ዕያሱስሜ', 7.614574842925677e-18),\n",
       " ('ዕጀሱጽሜ', 7.018528586437527e-18),\n",
       " ('ዕጀሱስሜ', 5.757770334572038e-18),\n",
       " ('ዕጃሱጽሜ', 5.721845260082377e-18)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_transcriptions(\"ijasusme\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install python-levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EVALUATION\n",
    "\n",
    "import Levenshtein\n",
    "from statistics import mean\n",
    "\n",
    "# this function takes two files (parallel texts) and generates\n",
    "# two lists after stripping beginning/trailing whitespace\n",
    "def extract_from_files(ethiopic_file, latin_file):\n",
    "    eth_file = open(ethiopic_file)\n",
    "    lat_file = open(latin_file)\n",
    "    ethiopic = [line.rstrip() for line in eth_file.readlines()]\n",
    "    latin = [line.rstrip() for line in lat_file.readlines()] \n",
    "\n",
    "    ethiopic = list(ethiopic)\n",
    "    latin = list(latin)\n",
    "\n",
    "    return ethiopic, latin\n",
    "\n",
    "# this function takes two parallel lists and evaluates how\n",
    "# our model performs\n",
    "def evaluate(ethiopic, latin):\n",
    "    accuracies = []\n",
    "\n",
    "    count = 0\n",
    "    for line in tqdm_notebook(latin):\n",
    "        predict = transliterate(line)\n",
    "        correct = ethiopic[count]\n",
    "        accuracy = Levenshtein.ratio(predict,correct)\n",
    "        accuracies.append(accuracy) \n",
    "        count += 1\n",
    "\n",
    "    return mean(accuracies)\n",
    "\n",
    "import re\n",
    "def evaluate_top_n(ethiopic, latin, top_n=2):\n",
    "    accuracies = []\n",
    "\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    paired = list(zip(ethiopic, latin))\n",
    "    for eth_line, lat_line in tqdm_notebook(paired):\n",
    "        eth_tokens = re.split('\\s+', eth_line.strip())\n",
    "        lat_tokens = re.split('\\s+', lat_line.strip())\n",
    "        for eth_token, lat_token in zip(eth_tokens, lat_tokens):\n",
    "            results = transliterate_word(lat_token, top_n=5)\n",
    "            if eth_token in results:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "    return correct/total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ethiopic_tot, latin_tot = extract_from_files(\"raw/original.txt\", \"raw/transliterated.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "ethiopic_2 = ethiopic_tot[0:10]\n",
    "latin_2 = latin_tot[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cached = {}\n",
    "#top_transcriptions(\"jadata\", 15, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eff0e2021f2e4738a7d2ef87455a3a4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.3725482577524574"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(ethiopic_2, latin_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "061dec13fd824c61bf8d3029aa32a04b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.07471264367816093"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_top_n(ethiopic_2, latin_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "ethiopic_3 = ethiopic_tot[0:100]\n",
    "latin_3 = latin_tot[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate(ethiopic_3, latin_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "ethiopic_manual, latin_manual = extract_from_files('parallel_data/taitu_am.txt','parallel_data/taitu_rom.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "552ae9cb532641e993a7267e8288c91b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=95), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.4873676417154896"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(ethiopic_manual[:100], latin_manual[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14d45c7c052346a2a2fc4f9f8682ab84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=95), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.14666666666666667"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_top_n(ethiopic_manual[:100], latin_manual[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "02-OpenNMT training by full sentences.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
